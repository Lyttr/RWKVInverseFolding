import subprocess
import random
import json
import os
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
from datasets import load_dataset

# ---------- å‚æ•°é…ç½® ----------
MIN_LEN = 80
MAX_LEN = 125
TRAIN_SIZE = 2000000
CHUNK_SIZE = 10000
NUM_THREADS = 8
RNAFOLD_CMD = "RNAfold"
OUTPUT_DIR = "/home/gaji/rna_dataset"
TEST_PATH = os.path.join(OUTPUT_DIR, "rna_test.json")
TRAIN_DIR = os.path.join(OUTPUT_DIR, "train_chunks")
MERGED_TRAIN_PATH = os.path.join(OUTPUT_DIR, "rna_train.json")

# ---------- å·¥å…·å‡½æ•° ----------
def generate_random_rna_sequence(n):
    return ''.join(random.choices('AUGC', k=n))

def run_rnafold(seq):
    try:
        result = subprocess.run(
            [RNAFOLD_CMD, "--noPS"],
            input=seq + "\n",
            capture_output=True,
            text=True,
            timeout=3
        )
        if result.returncode != 0:
            return None
        lines = result.stdout.strip().split('\n')
        if len(lines) >= 2:
            dot = lines[1].split()[0]
            return dot
    except:
        return None
    return None

def is_valid_structure(dot):
    return bool(dot and set(dot) != {'.'})

def save_json(data, path):
    with open(path, "w") as f:
        json.dump(data, f, indent=2)

def load_json(path):
    if not os.path.exists(path):
        return None
    with open(path, "r") as f:
        return json.load(f)

# ---------- æ•°æ®ç”Ÿæˆ ----------
def generate_and_validate(test_structures):
    seq = generate_random_rna_sequence(random.randint(MIN_LEN, MAX_LEN))
    dot = run_rnafold(seq)
    if is_valid_structure(dot) and dot not in test_structures:
        return {"sequence": seq, "structure": dot}
    return None

def generate_train_set(test_structures):
    os.makedirs(TRAIN_DIR, exist_ok=True)
    existing_chunks = sorted([f for f in os.listdir(TRAIN_DIR) if f.endswith(".json")])
    completed = len(existing_chunks) * CHUNK_SIZE
    print(f"ğŸ“¦ å·²å­˜åœ¨è®­ç»ƒé›†æ ·æœ¬æ•°: {completed}ï¼Œç›®æ ‡æ€»æ•°: {TRAIN_SIZE}")

    chunk_idx = len(existing_chunks)

    with tqdm(total=TRAIN_SIZE, desc="ç”Ÿæˆè®­ç»ƒé›†", initial=completed) as pbar:
        while completed < TRAIN_SIZE:
            train_data = []
            with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:
                futures = [executor.submit(generate_and_validate, test_structures) for _ in range(CHUNK_SIZE * 2)]
                for future in as_completed(futures):
                    item = future.result()
                    if item:
                        train_data.append(item)
                        completed += 1
                        pbar.update(1)
                        if len(train_data) >= CHUNK_SIZE:
                            break

            if train_data:
                path = os.path.join(TRAIN_DIR, f"train_chunk_{chunk_idx:05d}.json")
                save_json(train_data, path)
                print(f"save to train_chunk_{chunk_idx:05d}.json")
                chunk_idx += 1

    print(f"âœ… å®Œæˆè®­ç»ƒé›†ç”Ÿæˆï¼Œå…± {TRAIN_SIZE} æ¡æ ·æœ¬ï¼Œå­˜å‚¨åœ¨ {TRAIN_DIR}/")

    # åˆå¹¶æ‰€æœ‰ chunk
    merged = []
    print("ğŸ”„ æ­£åœ¨åˆå¹¶æ‰€æœ‰è®­ç»ƒé›†åˆ†å—...")
    for fname in sorted(os.listdir(TRAIN_DIR)):
        if fname.endswith(".json"):
            data = load_json(os.path.join(TRAIN_DIR, fname))
            merged.extend(data)
    save_json(merged, MERGED_TRAIN_PATH)
    print(f"âœ… å·²åˆå¹¶ä¸º {MERGED_TRAIN_PATH}ï¼Œå…± {len(merged)} æ¡æ ·æœ¬")

# ---------- ä¸»å‡½æ•° ----------
def main():
    # åŠ è½½ eternabench-cm æ•°æ®é›†
    dataset = load_dataset("multimolecule/eternabench-cm")

    # åˆå¹¶ train å’Œ test åˆ†åŒºä¸­çš„ç»“æ„ï¼Œè¿‡æ»¤é•¿åº¦ä¸è¶…è¿‡ 125ï¼Œå»é‡
    structures = set()
    structure_to_sequence = {}
    for split in ["train", "test"]:
        for entry in dataset[split]:
            structure = entry['secondary_structure']
            sequence = entry['sequence']
            if len(structure) <= 125 and structure not in structures:
                structures.add(structure)
                structure_to_sequence[structure] = sequence

    # æ„é€ æµ‹è¯•é›†ï¼Œä¿è¯ç»“æ„å”¯ä¸€
    test_data = [
        {"sequence": sequence, "structure": structure}
        for structure, sequence in structure_to_sequence.items()
    ]

    # ä¿å­˜æµ‹è¯•é›†
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    save_json(test_data, TEST_PATH)
    print(f"âœ… å·²ä¿å­˜æµ‹è¯•é›†ï¼Œå…± {len(test_data)} æ¡æ ·æœ¬ï¼Œè·¯å¾„ä¸º {TEST_PATH}")

    # ç”Ÿæˆè®­ç»ƒé›†
    generate_train_set(structures)

if __name__ == "__main__":
    main()
